# –ó–∞–¥–∞–Ω–∏–µ 1

------------------------------------------------------------------------

–°–æ–∑–¥–∞–π—Ç–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å (–∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π), –∫–æ—Ç–æ—Ä–∞—è –æ–ø–∏—Å—ã–≤–∞–ª–∞ –±—ã —Å–≤—è–∑—å:

-   —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–¥–∏—É—Å–∞ –æ–ø—É—Ö–æ–ª–∏ –∏ —Å—Ä–µ–¥–Ω–µ–π –ø–ª–æ—â–∞–¥–∏;

-   —Å—Ä–µ–¥–Ω–µ–≥–æ –ø–µ—Ä–∏–º–µ—Ç—Ä–∞;

-   —Å—Ä–µ–¥–Ω–µ–π —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ—Å—Ç–∏.

–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫ (–∏–ª–∏ –≥—Ä–∞—Ñ–∏–∫–∏, –µ—Å–ª–∏ –º–æ–¥–µ–ª–µ–π –Ω–µ—Å–∫–æ–ª—å–∫–æ), –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ—Ç—Ä–∞–∑–∏—Ç–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –ø—Ä—è–º—É—é, –∏ –ø—Ä–æ–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å–≤–æ–∏ –Ω–∞—Ö–æ–¥–∫–∏.

------------------------------------------------------------------------

–ë—ã–ª–∏ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω—ã –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏:

1.  Univariate regression - —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ 1 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞

2.  Multivariate regression- —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –ø—Ä–µ—Å–¥–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª–µ–µ 1 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞

------------------------------------------------------------------------

–í –∫–∞—á–µ—Å—Ç–≤–µ –º–æ–¥–µ–ª–µ–π –±—ã–ª–∏ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω—ã:

-   –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è

-   –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (2-–≥–æ –ø–æ—Ä—è–¥–∫–∞)

-   –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å

-   XGBoost

------------------------------------------------------------------------

–ù–∞—á–Ω–µ–º —Å Univariate regression

```{r}
# –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
library(ggplot2)
library(dplyr)
library(caret)
library(broom)
library(Metrics)
library(randomForest)
library(xgboost)

df <- read.csv("wisconsin_breast_cancer.csv")
features <- c("area_mean", "perimeter_mean", "symmetry_mean")
target <- "radius_mean"

compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true),
    stringsAsFactors = FALSE
  )
}

results <- data.frame()
model_list <- c("Linear", "Polynomial", "Random Forest", "XGBoost")

for (model_type in model_list) {
  cat("\n======", model_type, "Regression ======\n")
  par(mfrow = c(1, 3))  # 3 –≥—Ä–∞—Ñ–∏–∫–∞ –≤ —Ä—è–¥

  for (feature in features) {
    df_sub <- df[, c(feature, target)]
    names(df_sub) <- c("X", "Y")

    set.seed(42)
    trainIndex <- createDataPartition(df_sub$Y, p = .8, list = FALSE)
    train <- df_sub[trainIndex, ]
    test  <- df_sub[-trainIndex, ]

    if (model_type == "Linear") {
      model <- lm(Y ~ X, data = train)
      pred <- predict(model, newdata = test)
    } else if (model_type == "Polynomial") {
      model <- lm(Y ~ poly(X, 2), data = train)
      pred <- predict(model, newdata = test)
    } else if (model_type == "Random Forest") {
      model <- randomForest(Y ~ X, data = train)
      pred <- predict(model, newdata = test)
    } else if (model_type == "XGBoost") {
      dtrain <- xgb.DMatrix(data = as.matrix(train$X), label = train$Y)
      dtest <- xgb.DMatrix(data = as.matrix(test$X), label = test$Y)
      param <- list(objective = "reg:squarederror", max_depth = 3, eta = 0.1)
      model <- xgb.train(param, dtrain, nrounds = 100)
      pred <- predict(model, dtest)
    }

    metrics <- compute_metrics(test$Y, pred)
    metrics$Model <- model_type
    metrics$Feature <- feature
  
    results <- rbind(results, metrics)

    plot(test$X, test$Y, main = paste(feature, "‚Üí", target),
         xlab = feature, ylab = "Target", pch = 16, col = rgb(0, 0, 0, 0.5))
    points(test$X, pred, col = "red", pch = 16)
    legend("topleft", legend = c("Actual", "Predicted"), col = c("black", "red"), pch = 16)
  }
}

# –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ R¬≤
sorted_results <- results %>%
  arrange(Feature, desc(R2)) %>%
  mutate(across(where(is.numeric), round, 4))

cat("\n–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –º–æ–¥–µ–ª—è–º:\n")
print(sorted_results)
View(sorted_results)
```

–í –ø–æ–¥—Ö–æ–¥–µ –≤—ã—à–µ, –º—ã –ø—ã—Ç–∞–ª–∏—Å—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–¥–∏—É—Å–∞ –æ–ø—É—Ö–æ–ª–∏, –æ—Å–Ω–æ–≤—ã–≤–∞—è –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ 3 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Å—Ä–µ–¥–Ω—è—è –ø–ª–æ—â–∞–¥—å, —Å—Ä–µ–¥–Ω–∏–π –ø–µ—Ä–∏–º–µ—Ç–µ—Ä, —Å—Ä–µ–¥–Ω—è—è —Å–∏–º–º–µ—Ç—Ä–∏—è)

–ö–∞–∫ –º—ã –º–æ–∂–µ–º –≤–∏–¥–µ—Ç—å –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∑–Ω–∞—á–µ–Ω–∏—è area_mean –∏ perimeter_mean –∑–Ω–∞—á–∏–º—ã —Å–≤—è–∑–∞–Ω—ã —Å —Ü–µ–ª–µ–≤—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º radius_mean, –≤—Å–µ –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞–∑–∞–ª–∏ —Ö–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (R\^2 = –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 0.98-0.99). –î–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–ø–æ–ª–Ω–µ –æ–∂–∏–¥–∞–µ–º, –≤–µ–¥—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–∂–µ–Ω–æ –≤—ã–≤–µ—Å—Ç–∏ –æ–¥–∏–Ω –∏–∑ –¥—Ä—É–≥–æ–≥–æ, —á—Ç–æ –±—É–¥–µ—Ç –ø–æ–∫–∞–∑–∞–Ω–æ –Ω–∏–∂–µ.

–û–¥–Ω–∞–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä —Å—Ä–µ–¥–Ω–µ–π —Å–∏–º–º–µ—Ç—Ä–∏–∏ –Ω–µ –∏–º–µ–µ—Ç —Ç–∞–∫–∏—Ö –≤—ã—Å–æ–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –º–µ—Ç—Ä–∏–∫, —á—Ç–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π –∏–Ω—Ç–µ—Ä–µ—Å—Å, —Å –∏—Å—Å–ª–µ–¥–æ–≤—Ç–µ–ª—å—Å–∫–æ–π —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è. –õ–∏—à—å 3 –º–æ–¥–µ–ª–∏ —Å–º–æ–≥–ª–∏ –≤—ã–π—Ç–∏ –Ω–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π R\^2, —Ç–æ –µ—Å—Ç—å –º–æ–∂–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ü–µ–ª–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä –µ–¥–≤–∞ —á—É—Ç—å –ª—É—á—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.

------------------------------------------------------------------------

–•–æ—Ç—å –º—ã —É–∂–µ –∏ –ø–æ–ª—É—á–∏–ª–∏ —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ Multivariate regression

```{r}
library(ggplot2)
library(dplyr)
library(caret)
library(Metrics)
library(randomForest)
library(xgboost)

df <- read.csv("wisconsin_breast_cancer.csv")

features <- c("area_mean", "perimeter_mean", "symmetry_mean")
target <- "radius_mean"
X <- df[, features]
y <- df[, target]

set.seed(42)
trainIndex <- createDataPartition(y, p = .8, list = FALSE)
X_train <- X[trainIndex, ]
X_test  <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test  <- y[-trainIndex]

compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true),
    stringsAsFactors = FALSE
  )
}


model_defs <- list(
  "Linear Regression" = function() lm(y_train ~ ., data = X_train),
  "Polynomial Regression" = function() lm(y_train ~ poly(area_mean, 2) + poly(perimeter_mean, 2) + poly(symmetry_mean, 2), data = X_train),
  "Random Forest" = function() randomForest(y_train ~ ., data = X_train),
  "XGBoost" = function() {
    dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
    param <- list(objective = "reg:squarederror", max_depth = 3, eta = 0.1)
    model <- xgb.train(param, dtrain, nrounds = 100)
    model
  }
)

results <- list()

for (model_name in names(model_defs)) {
  print(paste("\n======", model_name, "====="))
  
  model_creator <- model_defs[[model_name]]
  model <- model_creator()
  
  if (model_name == "XGBoost") {
    dtest <- xgb.DMatrix(data = as.matrix(X_test))
    pred <- predict(model, dtest)
  } else {
    pred <- predict(model, newdata = X_test)
  }
  
  metrics <- compute_metrics(y_test, pred)
  metrics$Model <- model_name
  metrics$Feature <- paste(features, collapse = ", ")
  results[[length(results) + 1]] <- metrics
  
  print(
    ggplot(data.frame(y_test, pred), aes(x = y_test, y = pred)) +
      geom_point(alpha = 0.5) +
      geom_abline(slope = 1, intercept = 0, col = 'red') +
      ggtitle(paste(model_name, " ‚Äî All Features ‚Üí", target)) +
      xlab("Actual") + ylab("Predicted") +
      theme_minimal()
  )
}

results_df <- do.call(rbind, results) %>% 
  as.data.frame() %>%
  mutate(across(where(is.numeric), round, 4)) %>%
  arrange(desc(R2))

cat("\n–ú–µ—Ç—Ä–∏–∫–∏ Multivariate regression:\n")
print(results_df, n = Inf)

```

–ö–∞–∫ –∏ –æ–∂–∏–¥–∞–ª–æ—Å—å, –µ—Å–ª–∏ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏ —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫ –ª–∏–Ω–µ–π–Ω–æ –∑–∞–≤–∏—Å–∏–º –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Ç–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏—è —Ç–∞–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Ç–æ–∂–µ –±—É–¥–µ—Ç –ª–∏–Ω–µ–π–Ω–∞ –∑–∞–≤–∏—Å–∏–º–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–ª–æ–≥–∏—á–Ω—ã–µ –ø–µ—Ä–≤–æ–º—É –≤–∞—Ä–∏–∞–Ω—Ç—É —Ä–µ—à–µ–Ω–∏—è.

------------------------------------------------------------------------

–ö–∞–∫ —É–ø–æ–º–∏–Ω–∞–ª–æ—Å—å —Ä–∞–Ω–µ–µ, –æ–±—É—á–∞–µ–º—ã –∏ —Ü–µ–ª–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ª–∏–Ω–µ–π–Ω–æ –∑–∞–≤–∏—Å–∏–º—ã, –ø–æ—Ç–æ–º—É —á—Ç–æ –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥—Ä—É–≥ –¥—Ä—É–≥–∞. –í —Ç–∞–∫–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, –∫–æ–≥–¥–∞ –µ—Å—Ç—å –≤—Å–µ –Ω–∞–±–æ—Ä—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ—Ü–µ–ª–µ—Å–æ–æ–±—Ä–∞–∑–Ω–æ, –≤–µ–¥—å –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –ø–æ–ª—É—á–∏—Ç—å –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å. –ß—Ç–æ –±—É–¥–µ—Ç –ø–æ–∫–∞–∑–∞–Ω–æ –Ω–∏–∂–µ

```{r}
library(ggplot2)
library(Metrics)

df <- read.csv("wisconsin_breast_cancer.csv")
df$radius_estimated <- sqrt(df$area_mean / pi)

y_true <- df$radius_mean
y_pred <- df$radius_estimated

mae <- mae(y_true, y_pred)
mse <- mse(y_true, y_pred)
rmse <- sqrt(mse)
r2 <- R2(y_pred, y_true)

cat("–†–∞—Å—á—ë—Ç radius_mean —á–µ—Ä–µ–∑ area_mean:\n")
cat(sprintf("MAE:  %.4f\n", mae))
cat(sprintf("MSE:  %.4f\n", mse))
cat(sprintf("RMSE: %.4f\n", rmse))
cat(sprintf("R¬≤:   %.4f\n", r2))

ggplot(df, aes(x = radius_mean, y = radius_estimated)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(x = "–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π radius_mean", y = "–†–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–π radius_estimated", 
       title = "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π vs –†–∞—Å—á—ë—Ç–Ω—ã–π —Ä–∞–¥–∏—É—Å") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

–ú—ã —Ä–∞—Å—Å—á–∏—Ç–∞–ª–∏ —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–¥–∏—É—Å —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä area_mean –∏ –ø–æ–ª—É—á–∏–ª–∏ r\^2 –±–ª–∏–∑–∫–∏–π –∫ –µ–¥–∏–Ω–∏—Ü—ã, —á.—Ç.–¥

------------------------------------------------------------------------

–ê–Ω–∞–ª–æ–∏–≥—á–Ω—ã–º –æ–±—Ä–∞–∑–æ–º —Ä–∞—Å—Å—á–∏—Ç–∞–µ–º –ø–µ—Ä–∏–º–µ—Ç—Ä, —á–µ—Ä–µ–∑ —Ä–∞–¥–∏—É—Å

```{r}
library(ggplot2)
library(Metrics)

df <- read.csv("wisconsin_breast_cancer.csv")

df$perimeter_estimated <- 2 * pi * df$radius_mean

y_true <- df$perimeter_mean
y_pred <- df$perimeter_estimated

mae <- mae(y_true, y_pred)
mse <- mse(y_true, y_pred)
rmse <- sqrt(mse)
r2 <- R2(y_pred, y_true)

cat("–†–∞—Å—á—ë—Ç perimeter_mean —á–µ—Ä–µ–∑ radius_mean:\n")
cat(sprintf("MAE:  %.4f\n", mae))
cat(sprintf("MSE:  %.4f\n", mse))
cat(sprintf("RMSE: %.4f\n", rmse))
cat(sprintf("R¬≤:   %.4f\n", r2))

ggplot(df, aes(x = perimeter_mean, y = perimeter_estimated)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(x = "–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π perimeter_mean", y = "–†–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–π perimeter_estimated", 
       title = "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π vs –†–∞—Å—á—ë—Ç–Ω—ã–π –ø–µ—Ä–∏–º–µ—Ç—Ä") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

–ü–æ–ª—É—á–∏–ª–∏ r\^2 –±–ª–∏–∑–∫–∏–π –∫ –µ–¥–∏–Ω–∏—Ü—ã, —á.—Ç.–¥

------------------------------------------------------------------------

–ú—ã –≤—ã—è—Å–Ω–∏–ª–∏, —á—Ç–æ –º—ã –º–æ–∂–µ–º –ª–µ–≥–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—Ç—å —Ç–∞–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–∫ area_mean, perimeter_mean, radius_mean.

–ù–æ –≤—Å–ø–æ–º–Ω–∏–º —Ç–∞–∫–∂–µ, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–∏–º–º–µ—Ç—Ä–∏–∏, –∫–æ—Ç–æ—Ä–æ–µ –∏–º–µ–µ—Ç —Å–ª–∞–±—É—é –ª–∏–Ω–µ–π–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏.

–° –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è, –±—ã–ª–æ –±—ã –ø–æ–ª–µ–∑–Ω–æ —É–∑–Ω–∞—Ç—å, –º–æ–∂–µ–º –ª–∏ –º—ã –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ. –¢–∞–∫ –∫–∞–∫ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –æ—á–µ–≤–∏–¥–Ω–æ, —á—Ç–æ –ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –º–µ–∂–¥—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º –∏ –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –Ω–µ—Ç, —Å—Ä–∞–∑—É –ø–µ—Ä–µ–π–¥–µ–º –∫ –∏—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏.

–ü–æ–ø—Ä–æ–±—É–µ–º —ç—Ç–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–≤ Multivariate –ø–æ–¥—Ö–æ–¥

```{r}
library(ggplot2)
library(caret)
library(randomForest)
library(xgboost)
library(Metrics)

df <- read.csv("wisconsin_breast_cancer.csv")
features <- c("area_mean", "perimeter_mean", "radius_mean")
target <- "symmetry_mean"

X <- df[, features]
y <- df[, target]

set.seed(42)
trainIndex <- createDataPartition(y, p = .8, list = FALSE)
X_train <- X[trainIndex, ]
X_test  <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test  <- y[-trainIndex]

compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true)
  )
}

model_defs <- list(
  "Linear Regression" = function() lm(y_train ~ ., data = X_train),
  "Polynomial Regression" = function() lm(y_train ~ poly(area_mean, 2) + poly(perimeter_mean, 2) + poly(radius_mean, 2), data = X_train),
  "Random Forest" = function() randomForest(y_train ~ ., data = X_train),
  "XGBoost" = function() {
    dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
    param <- list(objective = "reg:squarederror", max_depth = 3, eta = 0.1)
    model <- xgb.train(param, dtrain, nrounds = 100)
    model
  }
)

results <- list()

for (model_name in names(model_defs)) {
  print(paste("\n======", model_name, "====="))
  
  model_creator <- model_defs[[model_name]]
  model <- model_creator()
  
  if (model_name == "XGBoost") {
    dtest <- xgb.DMatrix(data = as.matrix(X_test))
    pred <- predict(model, dtest)
  } else {
    pred <- predict(model, newdata = X_test)
  }
  
  metrics <- compute_metrics(y_test, pred)
  metrics$Model <- model_name
  results[[length(results) + 1]] <- metrics

  print(
      ggplot(data.frame(y_test, pred), aes(x = y_test, y = pred)) +
        geom_point(alpha = 0.6) +
        geom_abline(slope = 1, intercept = 0, col = "red", linetype = "dashed") +
        ggtitle(paste(model_name, " ‚Äî All Features ‚Üí", target)) +
        xlab("Actual") + ylab("Predicted") +
        theme_minimal() +
        theme(plot.title = element_text(hjust = 0.5))
    )
}

results_df <- do.call(rbind, results)
results_df$Model <- as.character(results_df$Model)  # Ensure Model is character
results_df <- results_df[order(-results_df$R2), ]  # Sort by R2 descending

numeric_cols <- sapply(results_df, is.numeric)
results_df[numeric_cols] <- round(results_df[numeric_cols], 4)

cat("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –í–∞—Ä–∏–∞–Ω—Ç–∞ 2:\n")
print(results_df)
```

R\^2 –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∞—è –¥–æ–ª—è –≤–∞—Ä–∏–∞—Ü–∏–∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–±—ä—è—Å–Ω—è–µ—Ç—Å—è –º–æ–¥–µ–ª—å—é. –ú—ã –≤–∏–¥–∏–º —á—Ç–æ R\^2 –ø—Ä–∏–Ω–∏–º–∞–µ—Ç "–∫—Ä–µ–ø–∫–æ–µ" –∑–Ω–∞—á–∏–º–æ–µ –æ—Ç –Ω—É–ª—è –∑–Ω–∞—á–µ–Ω–∏–µ —É —Ä—è–¥–∞ –º–æ–¥–µ–ª–µ–π.

Polynomial regression —è–≤–ª—è–µ—Ç—Å—è –ª—É—á—à–µ–π –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º —Å R\^2 = 0.4013. –•–æ—Ç—è —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∏–∂–µ, —á–µ–º —Ö–æ—Ç–µ–ª–æ—Å—å –±—ã, —ç—Ç–æ –≤—Å–µ —Ä–∞–≤–Ω–æ –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π, —á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –º–æ–¥–µ–ª—å –æ–±—ä—è—Å–Ω—è–µ—Ç –Ω–∞–∏–±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –≤–∞—Ä–∏–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö.

------------------------------------------------------------------------

–ù–æ –º—ã –ø–æ–π–¥–µ–º –¥–∞–ª—å—à–µ, –∏ –¥–æ–±–∞–≤–∏–º –≤ –º–æ–¥–µ–ª—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∫–æ—Ç–æ—Ä—ã–µ —É –Ω–∞—Å –µ—Å—Ç—å

```{r}
library(caret)
library(randomForest)
library(xgboost)
library(Metrics)
library(ggplot2)

df <- read.csv("wisconsin_breast_cancer.csv")
df <- df[, colSums(is.na(df)) == 0]

target <- "symmetry_mean"
X <- df[, setdiff(names(df), c("diagnosis", "id", target))]
y <- df[, target]

set.seed(42)
trainIndex <- createDataPartition(y, p = .8, list = FALSE)
X_train <- X[trainIndex, ]
X_test  <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test  <- y[-trainIndex]

compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true)
  )
}

model_defs <- list(
  "Linear Regression" = function() lm(y_train ~ ., data = X_train),
  "Polynomial Regression" = function() lm(y_train ~ poly(area_mean, 2) + poly(perimeter_mean, 2) + poly(radius_mean, 2), data = X_train),
  "Random Forest" = function() randomForest(y_train ~ ., data = X_train),
  "XGBoost" = function() {
    dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
    param <- list(objective = "reg:squarederror", max_depth = 3, eta = 0.1)
    model <- xgb.train(param, dtrain, nrounds = 100)
    model
  }
)

saved_models <- list()
results <- list()

for (model_name in names(model_defs)) {
  print(paste("\n======", model_name, "====="))
  
  model_creator <- model_defs[[model_name]]
  model <- model_creator()
  
  if (model_name == "XGBoost") {
    dtest <- xgb.DMatrix(data = as.matrix(X_test))
    pred <- predict(model, dtest)
  } else {
    pred <- predict(model, newdata = X_test)
  }
  
  saved_models[[model_name]] <- model
  
  metrics <- compute_metrics(y_test, pred)
  metrics$Model <- model_name
  results[[length(results) + 1]] <- metrics
  
  print(ggplot(data.frame(y_test, pred), aes(x = y_test, y = pred)) +
    geom_point(alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, col = "red", linetype = "dashed") +
    ggtitle(paste(model_name, " ‚Äî All Features ‚Üí", target)) +
    xlab("Actual") + ylab("Predicted") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5)))
}

results_df <- do.call(rbind, results)
results_df$Model <- as.character(results_df$Model)  # Ensure Model is character
results_df <- results_df[order(-results_df$R2), ]  # Sort by R2 descending

numeric_cols <- sapply(results_df, is.numeric)
results_df[numeric_cols] <- round(results_df[numeric_cols], 4)

cat("\n –ú–µ—Ç—Ä–∏–∫–∏ –í–∞—Ä–∏–∞–Ω—Ç–∞ 2:\n")
print(results_df)

```

–î–æ–±–∞–≤–∏–≤ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞–º —É–¥–∞–ª–æ—Å—å –¥–æ–≤–æ–ª—å–Ω–æ —Å–∏–ª—å–Ω–æ —É–ª—É—á—à–∏—Ç—å –Ω–∞—à–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è. –ù–æ —Ç–µ–ø–µ—Ä—å –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –ª–æ–≥–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–≤–ª–∏—è–ª–∏ –Ω–∞ —É–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞. –≠—Ç–æ –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å.

```{r}
xgb_importance <- xgb.importance(model = saved_models[["XGBoost"]])

print(xgb_importance)

xgb.plot.importance(importance_matrix = xgb_importance, 
                    top_n = 10, 
                    main = "Top 10 Most Important Features for XGBoost")

```

–ú—ã –ø–æ–ª—É—á–∏–ª–∏ –æ—á–µ–Ω—å –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, —á—Ç–æ –µ—Å—Ç—å –Ω–µ–∫–∏–π –ø—Ä–∏–∑–Ω–∞–∫ symmetry_worst, –∫–æ—Ç–æ—Ä—ã–π –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–æ –≤–ª—è–µ—Ç –Ω–∞ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é. –ò–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ, —á—Ç–æ —ç—Ç–æ –Ω–µ–∫–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç, —á—Ç–æ –Ω–∞–ø—Ä—è–º—É—é –≤–ª–∏—è–µ—Ç –Ω–∞ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ—Å—Ç—å –∏–ª–∏ –∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ—Å—Ç—å. –ü–æ—ç—Ç–æ–º—É –±—ã–ª–æ –±—ã —á–µ—Å—Ç–Ω–æ –∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ, —É–¥–∞–ª–∏—Ç—å —ç—Ç–æ—Ç –ø—Ä–∏–∑–Ω–∞–∫, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, —Å–º–æ–∂–µ–º –ª–∏ –º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥—Ä—É–≥–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å—Ä–µ–¥–Ω—é—é —Å–∏–º–º–µ—Ç—Ä–∏—é.

```{r}
library(caret)
library(randomForest)
library(xgboost)
library(Metrics)
library(ggplot2)

df <- read.csv("wisconsin_breast_cancer.csv")
df <- df[, colSums(is.na(df)) == 0]

target <- "symmetry_mean"
X <- df[, setdiff(names(df), c("diagnosis", "id", "symmetry_worst", target))]
y <- df[, target]

set.seed(42)
trainIndex <- createDataPartition(y, p = .8, list = FALSE)
X_train <- X[trainIndex, ]
X_test  <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test  <- y[-trainIndex]

compute_metrics <- function(true, pred) {
  data.frame(
    MAE = mae(true, pred),
    MSE = mse(true, pred),
    RMSE = rmse(true, pred),
    R2 = R2(pred, true)
  )
}

model_defs <- list(
  "Linear Regression" = function() lm(y_train ~ ., data = X_train),
  "Polynomial Regression" = function() lm(y_train ~ poly(area_mean, 2) + poly(perimeter_mean, 2) + poly(radius_mean, 2), data = X_train),
  "Random Forest" = function() randomForest(y_train ~ ., data = X_train),
  "XGBoost" = function() {
    dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train)
    param <- list(objective = "reg:squarederror", max_depth = 3, eta = 0.1)
    model <- xgb.train(param, dtrain, nrounds = 100)
    model
  }
)

saved_models <- list()
results <- list()

for (model_name in names(model_defs)) {
  print(paste("\n======", model_name, "====="))

  model_creator <- model_defs[[model_name]]
  model <- model_creator()
  
  if (model_name == "XGBoost") {
    dtest <- xgb.DMatrix(data = as.matrix(X_test))
    pred <- predict(model, dtest)
  } else {
    pred <- predict(model, newdata = X_test)
  }
  
  saved_models[[model_name]] <- model
  metrics <- compute_metrics(y_test, pred)
  metrics$Model <- model_name
  results[[length(results) + 1]] <- metrics
  
  print(ggplot(data.frame(y_test, pred), aes(x = y_test, y = pred)) +
    geom_point(alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, col = "red", linetype = "dashed") +
    ggtitle(paste(model_name, " ‚Äî All Features ‚Üí", target)) +
    xlab("Actual") + ylab("Predicted") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5)))
}

results_df <- do.call(rbind, results)
results_df$Model <- as.character(results_df$Model)  # Ensure Model is character
results_df <- results_df[order(-results_df$R2), ]  # Sort by R2 descending

numeric_cols <- sapply(results_df, is.numeric)
results_df[numeric_cols] <- round(results_df[numeric_cols], 4)

cat("\n –ú–µ—Ç—Ä–∏–∫–∏ –í–∞—Ä–∏–∞–Ω—Ç–∞ 2:\n")
print(results_df)
```

–¢–æ–∂–µ –Ω–µ–ø–ª–æ—Ö–æ, –Ω–æ –æ—á–µ–≤–∏–¥–Ω–æ —Ö—É–∂–µ –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ symmetry_worst –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ, –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ, –º–æ–∂–Ω–æ –Ω–∞—Ä—è–º—É—é –≤—ã—á–∏—Å–ª–∏—Ç—å —Å–∏–º–º–µ—Ç—Ä–∏—é (–ø–æ –ø–æ—Ä–æ–≥—É –Ω–∞–ø—Ä–∏–º–µ—Ä)

# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

------------------------------------------------------------------------

–ü—É—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ —Å –¥–∏–∞–≥–Ω–æ–∑–æ–º –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è: –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ–ø—É—Ö–æ–ª—å (M) ‚Äî 1, –∞ –¥–æ–±—Ä–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è (B) ‚Äî 0. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å (–∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π), –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–ª–∞ –±—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø—É—Ö–æ–ª–∏: –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–¥–∏—É—Å–∞; —Å—Ä–µ–¥–Ω–µ–π –ø–ª–æ—â–∞–¥–∏; —Å—Ä–µ–¥–Ω–µ–π —Ç–µ–∫—Å—Ç—É—Ä—ã. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏. –°–æ–∑–¥–∞–π—Ç–µ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–ª–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø—É—Ö–æ–ª–∏ –æ—Ç –≤—Å–µ—Ö —Ç—Ä–µ—Ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤.

------------------------------------------------------------------------

–ó–¥–µ—Å—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ —Å—Ç—Ä–æ–∏—Ç—Å—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è. –û—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º AUC –∏ Accuracy.

–°—Ç—Ä–æ–∏—Ç—Å—è –≥—Ä–∞—Ñ–∏–∫,–∫–∞–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞.

------------------------------------------------------------------------

–î–∞–ª–µ–µ –º—ã —Å—Ç—Ä–æ–∏–º –º–æ–¥–µ–ª—å –ø–æ –≤—Å–µ–º —Ç—Ä—ë–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º –í—ã—á–∏—Å–ª—è—é—Ç—Å—è AUC, Accuracy, –∏ Classification Report.

–°—Ç—Ä–æ—è—Ç—Å—è: ROC-–∫—Ä–∏–≤–∞—è (–æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏), –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (confusion matrix).

```{r}
library(caret)
library(pROC)
library(ggplot2)
library(reshape2)
library(e1071)

df <- read.csv("wisconsin_breast_cancer.csv")

df$diagnosis_binary <- ifelse(df$diagnosis == "M", 1, 0)

features <- c("radius_mean", "area_mean", "texture_mean")
X_all <- df[, features]
y <- df$diagnosis_binary

set.seed(42)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
X_train_all <- X_all[trainIndex, ]
X_test_all <- X_all[-trainIndex, ]
y_train <- y[trainIndex]
y_test <- y[-trainIndex]

for (feature in features) {
  X <- df[, feature, drop = FALSE]
  trainIndex_f <- createDataPartition(y, p = 0.8, list = FALSE)
  X_train <- X[trainIndex_f, , drop = FALSE]
  X_test <- X[-trainIndex_f, , drop = FALSE]
  y_train_f <- y[trainIndex_f]
  y_test_f <- y[-trainIndex_f]
  
  model <- glm(y_train_f ~ ., data = data.frame(X_train, y_train_f), family = binomial())
  
  probs <- predict(model, newdata = X_test, type = "response")
  
  roc_curve <- roc(y_test_f, probs)
  auc <- auc(roc_curve)  # AUC –∏–∑ pROC
  pred <- ifelse(probs > 0.5, 1, 0)
  acc <- mean(pred == y_test_f)
  
  cat("\n–ú–æ–¥–µ–ª—å –ø–æ –ø—Ä–∏–∑–Ω–∞–∫—É:", feature, "\n")
  cat("AUC:", auc, "| Accuracy:", acc, "\n")
  
  print(ggplot(data.frame(X_test, probs, y_test_f), aes(x = X_test[[feature]], y = probs,     color = as.factor(y_test_f))) +
    geom_point(alpha = 0.7) +
    labs(title = paste("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –æ—Ç", feature), 
         x = feature, y = "P(Malignant)") +
    theme_minimal() +
    scale_color_manual(values = c("blue", "red")))
}

plot(roc_curve_all, main = "ROC-–∫—Ä–∏–≤–∞—è –¥–ª—è –º–æ–¥–µ–ª–∏ –ø–æ –≤—Å–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º", 
     col = "red", lwd = 2)
legend("bottomright", legend = paste("AUC =", round(auc_all, 3)), 
       col = "red", lwd = 2)

model_all <- glm(y_train ~ ., data = data.frame(X_train_all, y_train), family = binomial())
probs_all <- predict(model_all, newdata = X_test_all, type = "response")

roc_curve_all <- roc(y_test, probs_all)
auc_all <- auc(roc_curve_all)
pred_all <- ifelse(probs_all > 0.5, 1, 0)
acc_all <- mean(pred_all == y_test)

cat("\n–ú–æ–¥–µ–ª—å –ø–æ –≤—Å–µ–º —Ç—Ä—ë–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º:\n")
cat("AUC:", auc_all, "| Accuracy:", acc_all, "\n")

conf_matrix <- table(Predicted = pred_all, Actual = y_test)

conf_matrix_df <- as.data.frame(conf_matrix)
names(conf_matrix_df) <- c("Predicted", "Actual", "Count")

ggplot(conf_matrix_df, aes(x = Predicted, y = Actual, fill = Count)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Count), color = "white", size = 5) +
  labs(title = "–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫", 
       x = "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å", 
       y = "–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å") +
  theme_minimal() +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  coord_fixed()

```

area_mean –∏ radius_mean –ø–æ–∫–∞–∑–∞–ª–∏ –ø–æ—á—Ç–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–π AUC (\~0.91 - 0.94) –∏ —Ç–æ—á–Ω–æ—Å—Ç—å—é \~85 - 88%.

texture_mean –∑–∞–º–µ—Ç–Ω–æ —É—Å—Ç—É–ø–∞–µ—Ç ‚Äî AUC –≤—Å–µ–≥–æ 0.75 –∏ —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∏–∂–µ 65%, —Ç–æ –µ—Å—Ç—å —ç—Ç–æ—Ç –ø—Ä–∏–∑–Ω–∞–∫ —Å–∞–º –ø–æ —Å–µ–±–µ —Å–ª–∞–±–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–µ–Ω.

–ú–æ–¥–µ–ª—å –Ω–∞ —Ç—Ä—ë—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ: AUC: 0.9431, Accuracy: 0.876 (–ø—Ä–∏–º–µ—Ä–Ω–æ –∫–∞–∫ —É radius_mean).

–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–∞—ë—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ —Ç–µ –∂–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏, —á—Ç–æ –∏ –æ–¥–∏–Ω–æ—á–Ω—ã–µ —Å–∏–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.

------------------------------------------------------------------------

# 3 –∑–∞–¥–∞–Ω–∏–µ

------------------------------------------------------------------------

–†–∞—Å—Å—á–∏—Ç–∞–π—Ç–µ –≤—ã–±–æ—Ä–∫—É –¥–ª—è –≥–∏–ø–æ—Ç–µ–∑—ã equality –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è. –ú—ã —Ö–æ—Ç–∏–º —Å—Ä–∞–≤–Ω–∏—Ç—å –Ω–æ–≤—É—é —Ç–µ—Ä–∞–ø–∏—é –∏–Ω—Ñ–µ–∫—Ü–∏–∏, –ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è—é—â–µ–π—Å—è –≤ –±–æ–ª—å–Ω–∏—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö —É –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ —Å –æ–∂–æ–≥–∞–º–∏, —Å –∑–æ–ª–æ—Ç—ã–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–º, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –¥–∞–Ω–Ω—ã—Ö, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ö–æ–∫—Å–∞. –ü—É—Å—Ç—å –æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ ¬´–∑–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç / –Ω–æ–≤–∞—è —Ç–µ—Ä–∞–ø–∏—è¬ª, hazard ratio, HR = 2. –ú—ã –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ 80% –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ (d = 0,8) –º–æ–≥—É—Ç —Å—Ç–æ–ª–∫–Ω—É—Ç—å—Å—è —Å —ç—Ç–∏–º –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–µ–º. –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –≥—Ä—É–ø–ø —Ç–µ—Ä–∞–ø–∏–∏ —Ä–∞–≤–Ω—ã (p1 = p2 = 0,5).

![](images/clipboard-1580076354.png)

```{r}
library(MASS)

# –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è 95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
Z <- qnorm(0.975)  # 0.975 –ø–æ—Ç–æ–º—É —á—Ç–æ –º—ã —Å–º–æ—Ç—Ä–∏–º –Ω–∞ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã (–¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π —Ç–µ—Å—Ç)

HR <- 2    # –æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤
p1 <- 0.5  # –¥–æ–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ –≤ –ø–µ—Ä–≤–æ–π –≥—Ä—É–ø–ø–µ
p2 <- 0.5  # –¥–æ–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ –≤–æ –≤—Ç–æ—Ä–æ–π –≥—Ä—É–ø–ø–µ
d <- 0.8   # –¥–æ–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å—Ç–æ–ª–∫–Ω—É—Ç—å—Å—è —Å –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–µ–º

ln_HR <- log(HR)
n_1_n_2 <- ((Z / 2 + Z) ^ 2) * (ln_HR ^ 2) * p1 * p2 * d
n_total <- n_1_n_2 * 2

# –†–µ–∑—É–ª—å—Ç–∞—Ç
cat(sprintf("–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã: %.0f\n", n_1_n_2))
cat(sprintf("–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏: %.0f\n", n_total))

```

–ù–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–∞–∫—Ç–∏–∫–µ —ç—Ç–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –º–∞–ª–æ

–ù–∏–∑–∫–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –º–æ—â–Ω–æ—Å—Ç–∏ ‚Äî –≤ —Ñ–æ—Ä–º—É–ª–µ –Ω–µ —É—á—Ç—ë–Ω –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç, –æ—Ç–≤–µ—á–∞—é—â–∏–π –∑–∞ –º–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞

–§–æ—Ä–º—É–ª–∞ —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è, –æ–Ω–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–Ω–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—á—ë—Ç–∞ –≤—ã–±–æ—Ä–∫–∏ –≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ö–æ–∫—Å–∞.

HR = 2 ‚Äî —ç—Ç–æ –±–æ–ª—å—à–æ–µ —Ä–∞–∑–ª–∏—á–∏–µ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏. –ß–µ–º —Å–∏–ª—å–Ω–µ–µ —ç—Ñ—Ñ–µ–∫—Ç, —Ç–µ–º –º–µ–Ω—å—à–µ –≤—ã–±–æ—Ä–∫–∞ –Ω—É–∂–Ω–∞ –¥–ª—è –µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è.

–ü–æ—ç—Ç–æ–º—É –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –≥–æ—Ç–æ–≤—ã–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤—ã–±–æ—Ä–∫–∏ –≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ö–æ–∫—Å–∞

------------------------------------------------------------------------

–ü–æ—Å—Ç—Ä–æ–∏–º —Å–ø–µ—Ä–≤–∞ –≥—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏—è —Ä–∏—Å–∫–æ–≤ (HR)

```{r}
library(survival)
library(ggplot2)

alpha <- 0.05
power <- 0.8
p <- 0.5
event_rate <- 0.8

hr_values <- seq(1.1, 3.0, length.out = 50)
sample_sizes <- numeric(length(hr_values))

sample_size_cph <- function(alpha, power, p, event_rate, HR) {
  log_HR <- log(HR)
  
  n_exp <- (qnorm(1 - alpha / 2) + qnorm(power))^2 * (p * (1 - p) + event_rate * (1 - event_rate)) / (log_HR^2)
  n_con <- n_exp
  
  return(n_exp + n_con)
}

for (i in 1:length(hr_values)) {
  HR <- hr_values[i]
  tryCatch({
    total_n <- sample_size_cph(alpha, power, p, event_rate, HR)
    sample_sizes[i] <- total_n
  }, error = function(e) {
    sample_sizes[i] <- NA 
  })
}


data <- data.frame(HR = hr_values, SampleSize = sample_sizes)
ggplot(data, aes(x = HR, y = SampleSize)) +
  geom_line() +
  geom_point() +
  labs(x = "Hazard Ratio (HR)", y = "–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏", title = " –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç Hazard Ratio") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(panel.grid.major = element_line(color = "gray", size = 0.5), panel.grid.minor = element_blank())

```

–ì—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç HR –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ –º–µ–Ω—è–µ—Ç—Å—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–∞—Ö.

–ö–æ–≥–¥–∞ HR = 1 - –≤—ã–±–æ—Ä–∫–∞ —Å—Ç—Ä–µ–º–∏—Ç—Å—è –∫ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏ (—Å–ª–æ–∂–Ω–æ –¥–æ–∫–∞–∑–∞—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —ç—Ñ—Ñ–µ–∫—Ç).

–ö–æ–≥–¥–∞ HR –±–æ–ª—å—à–æ–π (2‚Äì3) - —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–µ–Ω—å—à–µ –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤, —á—Ç–æ–±—ã –≤—ã—è–≤–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç.

------------------------------------------------------------------------

–¢–∞–∫–∂–µ –ø–æ—Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç –º–æ—â–Ω–æ—Å—Ç–∏ —Ç–µ—Å—Ç–∞ (power)

```{r}
library(ggplot2)

alpha <- 0.05
HR <- 2.0
log_HR <- log(HR)
p <- 0.5
event_rate <- 0.8

powers <- seq(0.6, 0.99, length.out = 40)
sample_sizes_power <- numeric(length(powers))

sample_size_power <- function(log_HR, power, alpha, p, event_rate) {
  Z <- qnorm(1 - alpha / 2) + qnorm(power)
  n <- (Z^2 * (p * (1 - p) + event_rate * (1 - event_rate))) / log_HR^2
  return(n)
}

for (i in 1:length(powers)) {
  pwr <- powers[i]
  n <- sample_size_power(log_HR, pwr, alpha, p, event_rate)
  sample_sizes_power[i] <- ceiling(n) * 2
}

data <- data.frame(Power = powers, SampleSize = sample_sizes_power)
ggplot(data, aes(x = Power, y = SampleSize)) +
  geom_line(color = "green") +
  geom_point(color = "green") +
  labs(x = "–ú–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞ (Power)", y = "–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏", title = "–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –æ—Ç –º–æ—â–Ω–æ—Å—Ç–∏ —Ç–µ—Å—Ç–∞") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(panel.grid.major = element_line(color = "gray", size = 0.5), panel.grid.minor = element_blank())

```

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ —Å–∏–ª—å–Ω–æ –≤–ª–∏—è–µ—Ç —Ç—Ä–µ–±—É–µ–º–∞—è –º–æ—â–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞.

–ß–µ–º –≤—ã—à–µ –º–æ—â–Ω–æ—Å—Ç—å - —Ç–µ–º –±–æ–ª—å—à–µ –≤—ã–±–æ—Ä–∫–∞ –Ω—É–∂–Ω–∞, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç. Power = 0.8 (80%) - —Å—Ç–∞–Ω–¥–∞—Ä—Ç –≤ –º–µ–¥–∏—Ü–∏–Ω–µ.

------------------------------------------------------------------------

–° –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –Ω–∞–º –±—ã–ª–æ –±—ã –∏–Ω—Ç–µ—Ä–µ—Å—Å–Ω–æ –ø–µ—Ä–µ–±—Ä–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –Ω–∞–±–æ—Ä—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –ø–æ—ç—Ç–æ–º—É —Ä–µ–∞–ª–∏–∑—É–µ–º —Å–ø–µ—Ä–≤–∞ —Å–∞–º–æ–ø–∏—Å–Ω—ã–π –ø–µ—Ä–µ–±–æ—Ä grid search, –∞ –∑–∞—Ç–µ–º –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –≥–æ—Ç–æ–≤—ã–º —Ä–µ—à–µ–Ω–∏–µ–º –∏ —Å—Ä–∞–≤–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

```{r}
library(dplyr)
library(tidyr)

sample_size_necessary <- function(hr, power, alpha, p_exp, p_con, ratio_of_participants) {
  Z <- qnorm(1 - alpha / 2) + qnorm(power)
  log_HR <- log(hr)
  n1_n2 <- (Z^2 * (p_exp * (1 - p_exp) + p_con * (1 - p_con))) / log_HR^2
  return(n1_n2)
}

hr_values <- seq(1.1, 3.0, by = 0.2)
power_values <- c(0.8, 0.85, 0.9)
event_rates <- c(0.6, 0.7, 0.8, 0.9)
alpha <- 0.05
p <- 0.5
ratio_of_participants <- 1

results <- list()

for (hr in hr_values) {
  for (power in power_values) {
    for (event_rate in event_rates) {
      tryCatch({
        n1_n2 <- sample_size_necessary(hr, power, alpha, p, p, ratio_of_participants)
        sample_size <- n1_n2 * 2
        adjusted_sample_size <- ceiling(sample_size / event_rate)
  
        results <- append(results, list(data.frame(
          HR = round(hr, 2),
          Power = power,
          Event_Rate = event_rate,
          Raw_Sample_Size = ceiling(sample_size),
          Adjusted_Sample_Size = adjusted_sample_size
        )))
      }, error = function(e) {
        cat("–û—à–∏–±–∫–∞ –ø—Ä–∏ HR =", hr, ", power =", power, ", event_rate =", event_rate, ": ", e$message, "\n")
      })
    }
  }
}

df_results <- bind_rows(results)

df_sorted <- df_results %>% arrange(Adjusted_Sample_Size)

print(head(df_sorted, 10))

```

```{r}
library(powerSurvEpi)
library(nloptr)

objective_function <- function(params) {
  hr <- params[1]
  power <- params[2]
  pC <- params[3]
  
  alpha <- 0.05
  ratio <- 1
  p <- 0.5
  
  tryCatch({
    sample_size <- ssizeCT.default(
      power = power,
      k = ratio,
      pE = pC * hr,
      pC = pC,
      RR = hr,
      alpha = alpha
    )
    adjusted_sample_size <- ceiling(sample_size)
    return(adjusted_sample_size)
  }, error = function(e) {
    print(paste("–û—à–∏–±–∫–∞ –≤ —Ä–∞—Å—á–µ—Ç–∞—Ö:", e$message))
    return(Inf)
  })
}


lower_bounds <- c(1.1, 0.8, 0.6)
upper_bounds <- c(3.1, 0.85, 0.9)

result <- nloptr::nloptr(
  x0 = c(1.5, 0.825, 0.75),
  eval_f = objective_function,
  lb = lower_bounds,
  ub = upper_bounds,
  opts = list(algorithm = "NLOPT_GN_CRS2_LM", maxeval = 100)
)

if (result$objective < Inf) {
  print(paste("–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (HR, power, pC):", paste(round(result$solution, 3), collapse = ", ")))
  print(paste("–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏:", result$objective))
} else {
  print("–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Ü–µ–ª–µ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é.")
}

```

–ö–∞–∫ –º—ã –≤–∏–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Å–æ—à–ª–∏—Å—å, —Ä—É—á–Ω–æ–π –ø–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–∏–ª —Å–ª–µ–¥—É—é—â–∏–π –Ω–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:

```         
  HR    Power   Event Rate     Adjusted Sample Size
  2.9   0.80    0.9            8
```

–í —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø—Ä–µ–¥–ª–æ–∂–∏–ª —Ç–∞–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã

```         
  HR     Power   Event Rate    Adjusted Sample Size
  3.1   0.83    0.9            9
```
